{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from termcolor import colored\n",
    "import requests\n",
    "import io\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import lru_cache\n",
    "import random\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from typing import Optional, Tuple, Dict, Any, List\n",
    "\n",
    "class RateLimiter:\n",
    "    def __init__(self, max_requests: int = 2000, time_window: int = 3600):\n",
    "        self.max_requests = max_requests\n",
    "        self.time_window = time_window\n",
    "        self.requests = []\n",
    "        self.lock = ThreadPoolExecutor(max_workers=1)\n",
    "\n",
    "    def wait_if_needed(self):\n",
    "        \"\"\"Check if we need to wait before making another request\"\"\"\n",
    "        current_time = time.time()\n",
    "        \n",
    "        def _cleanup_and_check():\n",
    "            # Remove old requests\n",
    "            while self.requests and current_time - self.requests[0] > self.time_window:\n",
    "                self.requests.pop(0)\n",
    "            \n",
    "            # Check if we're at the limit\n",
    "            if len(self.requests) >= self.max_requests:\n",
    "                sleep_time = self.requests[0] + self.time_window - current_time\n",
    "                if sleep_time > 0:\n",
    "                    time.sleep(sleep_time + random.uniform(0.1, 1.0))\n",
    "            \n",
    "            # Add new request timestamp\n",
    "            self.requests.append(current_time)\n",
    "\n",
    "        # Execute cleanup and check in a thread-safe manner\n",
    "        self.lock.submit(_cleanup_and_check).result()\n",
    "\n",
    "class StockAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.base_dir = 'stock_analysis'\n",
    "        self.stock_lists_dir = os.path.join(self.base_dir, 'stock_lists')\n",
    "        self.results_dir = os.path.join(self.base_dir, 'daily_results')\n",
    "        self.delisted_cache_file = os.path.join(self.stock_lists_dir, 'delisted_stocks.json')\n",
    "        self.setup_directories()\n",
    "        self.load_delisted_stocks()\n",
    "        self.rate_limiter = RateLimiter()\n",
    "        self.session = self._create_robust_session()\n",
    "        self.batch_size = 10  # Process stocks in smaller batches\n",
    "        self.retry_delay = 60  # Delay between retries in seconds\n",
    "        self.max_retries = 3   # Maximum number of retries per stock\n",
    "\n",
    "    def setup_directories(self):\n",
    "        \"\"\"Create necessary directories if they don't exist\"\"\"\n",
    "        os.makedirs(self.stock_lists_dir, exist_ok=True)\n",
    "        os.makedirs(self.results_dir, exist_ok=True)\n",
    "\n",
    "    def _create_robust_session(self) -> requests.Session:\n",
    "        \"\"\"Create a session with retry mechanism\"\"\"\n",
    "        session = requests.Session()\n",
    "        retries = Retry(\n",
    "            total=5,\n",
    "            backoff_factor=0.5,\n",
    "            status_forcelist=[429, 500, 502, 503, 504],\n",
    "            allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "        )\n",
    "        adapter = HTTPAdapter(max_retries=retries)\n",
    "        session.mount(\"http://\", adapter)\n",
    "        session.mount(\"https://\", adapter)\n",
    "        return session\n",
    "\n",
    "    def load_delisted_stocks(self):\n",
    "        \"\"\"Load previously identified delisted stocks\"\"\"\n",
    "        try:\n",
    "            with open(self.delisted_cache_file, 'r') as f:\n",
    "                self.delisted_stocks = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            self.delisted_stocks = {'NSE': [], 'BSE': []}\n",
    "            self.save_delisted_stocks()\n",
    "\n",
    "    def save_delisted_stocks(self):\n",
    "        \"\"\"Save delisted stocks to cache\"\"\"\n",
    "        with open(self.delisted_cache_file, 'w') as f:\n",
    "            json.dump(self.delisted_stocks, f)\n",
    "\n",
    "    def should_update_stock_list(self, exchange: str) -> bool:\n",
    "        \"\"\"Check if stock list needs updating (weekly update)\"\"\"\n",
    "        list_file = os.path.join(self.stock_lists_dir, f'{exchange}_stocks.json')\n",
    "        if not os.path.exists(list_file):\n",
    "            return True\n",
    "        file_time = datetime.fromtimestamp(os.path.getmtime(list_file))\n",
    "        return (datetime.now() - file_time).days >= 7\n",
    "\n",
    "    def save_stock_list(self, symbols: List[str], exchange: str):\n",
    "        \"\"\"Save stock list to JSON file\"\"\"\n",
    "        list_file = os.path.join(self.stock_lists_dir, f'{exchange}_stocks.json')\n",
    "        data = {\n",
    "            'symbols': symbols,\n",
    "            'last_updated': datetime.now().strftime('%Y-%m-%d')\n",
    "        }\n",
    "        with open(list_file, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "\n",
    "    def load_stock_list(self, exchange: str) -> List[str]:\n",
    "        \"\"\"Load stock list from JSON file\"\"\"\n",
    "        list_file = os.path.join(self.stock_lists_dir, f'{exchange}_stocks.json')\n",
    "        with open(list_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return data['symbols']\n",
    "\n",
    "    def download_nse_stocks(self) -> List[str]:\n",
    "        \"\"\"Download NSE stock list if needed\"\"\"\n",
    "        if self.should_update_stock_list('NSE'):\n",
    "            try:\n",
    "                url = \"https://archives.nseindia.com/content/equities/EQUITY_L.csv\"\n",
    "                response = self.session.get(url)\n",
    "                df = pd.read_csv(io.StringIO(response.content.decode('utf-8')))\n",
    "                symbols = df['SYMBOL'].tolist()\n",
    "                self.save_stock_list(symbols, 'NSE')\n",
    "                print(\"NSE stock list updated\")\n",
    "                return symbols\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading NSE stocks: {e}\")\n",
    "                if os.path.exists(os.path.join(self.stock_lists_dir, 'NSE_stocks.json')):\n",
    "                    return self.load_stock_list('NSE')\n",
    "                return []\n",
    "        return self.load_stock_list('NSE')\n",
    "\n",
    "    def download_bse_stocks(self) -> List[str]:\n",
    "        \"\"\"Download BSE stock list if needed\"\"\"\n",
    "        if self.should_update_stock_list('BSE'):\n",
    "            try:\n",
    "                url = \"https://www.bseindia.com/corporates/List_Scrips.aspx\"\n",
    "                response = self.session.get(url)\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                table = soup.find('table', {'id': 'ContentPlaceHolder1_tblData'})\n",
    "                symbols = []\n",
    "\n",
    "                if table:\n",
    "                    rows = table.find_all('tr')[1:]\n",
    "                    for row in rows:\n",
    "                        cols = row.find_all('td')\n",
    "                        if cols:\n",
    "                            bse_code = cols[0].text.strip()\n",
    "                            symbols.append(bse_code)\n",
    "\n",
    "                if symbols:\n",
    "                    self.save_stock_list(symbols, 'BSE')\n",
    "                    print(\"BSE stock list updated\")\n",
    "                    return symbols\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading BSE stocks: {e}\")\n",
    "                if os.path.exists(os.path.join(self.stock_lists_dir, 'BSE_stocks.json')):\n",
    "                    return self.load_stock_list('BSE')\n",
    "                return []\n",
    "        return self.load_stock_list('BSE')\n",
    "\n",
    "    @lru_cache(maxsize=1000)\n",
    "    def calculate_rsi(self, prices_tuple: Tuple[float, ...], periods: int = 14) -> float:\n",
    "        \"\"\"Calculate RSI with caching for performance\"\"\"\n",
    "        prices = pd.Series(prices_tuple)\n",
    "        delta = prices.diff()\n",
    "        gain = delta.where(delta > 0, 0).rolling(window=periods).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=periods).mean()\n",
    "        rs = gain / loss\n",
    "        return float(100 - (100 / (1 + rs)).iloc[-1])\n",
    "    \n",
    "    def calculate_ema(self, data: pd.DataFrame, length: int, source: str = 'Close', \n",
    "                     offset: int = 0, smoothing_length: int = 9) -> pd.Series:\n",
    "        \"\"\"Calculate Exponential Moving Average with specified parameters\"\"\"\n",
    "        try:\n",
    "            if isinstance(data, pd.Series):\n",
    "                series_data = data\n",
    "            else:\n",
    "                series_data = data[source]\n",
    "            \n",
    "            # Calculate SMA for initial smoothing\n",
    "            sma = series_data.rolling(window=smoothing_length).mean()\n",
    "            \n",
    "            # Calculate multiplier\n",
    "            multiplier = 2 / (length + 1)\n",
    "            \n",
    "            # Initialize EMA with SMA\n",
    "            ema = pd.Series(index=series_data.index, dtype=float)\n",
    "            ema.iloc[:length-1] = np.nan\n",
    "            ema.iloc[length-1] = sma.iloc[length-1]\n",
    "            \n",
    "            # Calculate EMA\n",
    "            for i in range(length, len(series_data)):\n",
    "                ema.iloc[i] = (series_data.iloc[i] - ema.iloc[i-1]) * multiplier + ema.iloc[i-1]\n",
    "            \n",
    "            # Apply offset if specified\n",
    "            if offset != 0:\n",
    "                ema = ema.shift(offset)\n",
    "            \n",
    "            return ema\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating EMA: {e}\")\n",
    "            return pd.Series(np.nan, index=data.index)\n",
    "\n",
    "    def calculate_tema(self, data: pd.DataFrame, length: int, source: str = 'Close') -> pd.Series:\n",
    "        \"\"\"Calculate Triple Exponential Moving Average (TEMA)\"\"\"\n",
    "        try:\n",
    "            # Get price series\n",
    "            if isinstance(data, pd.Series):\n",
    "                prices = data\n",
    "            else:\n",
    "                prices = data[source]\n",
    "            \n",
    "            # Calculate multiplier\n",
    "            multiplier = 2 / (length + 1)\n",
    "            \n",
    "            # Calculate EMA1\n",
    "            ema1 = prices.ewm(span=length, adjust=False).mean()\n",
    "            \n",
    "            # Calculate EMA2\n",
    "            ema2 = ema1.ewm(span=length, adjust=False).mean()\n",
    "            \n",
    "            # Calculate EMA3\n",
    "            ema3 = ema2.ewm(span=length, adjust=False).mean()\n",
    "            \n",
    "            # Calculate TEMA\n",
    "            tema = 3 * ema1 - 3 * ema2 + ema3\n",
    "            \n",
    "            # Replace first 'length' periods with NaN\n",
    "            tema.iloc[:length-1] = np.nan\n",
    "            \n",
    "            return tema\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating TEMA: {e}\")\n",
    "            return pd.Series(np.nan, index=data.index)\n",
    "\n",
    "    def get_stock_data(self, symbol: str, exchange: str = 'NSE', days: int = 200) -> Tuple[Optional[float], Optional[pd.DataFrame], Optional[float], Optional[Dict[str, Any]]]:\n",
    "        \"\"\"Fetch stock data with rate limiting and retries\"\"\"\n",
    "        if symbol in self.delisted_stocks[exchange]:\n",
    "            return None, None, None, None\n",
    "\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                # Wait if needed based on rate limits\n",
    "                self.rate_limiter.wait_if_needed()\n",
    "                \n",
    "                ticker_symbol = f\"{symbol}.NS\" if exchange == 'NSE' else f\"{symbol}.BO\"\n",
    "                ticker = yf.Ticker(ticker_symbol)\n",
    "                \n",
    "                # Add random delay between 1 and 3 seconds\n",
    "                time.sleep(random.uniform(1, 3))\n",
    "                \n",
    "                info = ticker.info\n",
    "                \n",
    "                end_date = datetime.now()\n",
    "                start_date = end_date - timedelta(days=days)\n",
    "\n",
    "                hist_data = ticker.history(\n",
    "                    start=start_date,\n",
    "                    end=end_date,\n",
    "                    interval=\"1d\"\n",
    "                )\n",
    "\n",
    "                if hist_data.empty:\n",
    "                    return None, None, None, None\n",
    "\n",
    "                # Calculate technical indicators\n",
    "                hist_data = self._calculate_technical_indicators(hist_data)\n",
    "                \n",
    "                latest_price = hist_data['Close'].iloc[-1]\n",
    "                prices_tuple = tuple(hist_data['Close'].values)\n",
    "                latest_rsi = self.calculate_rsi(prices_tuple)\n",
    "\n",
    "                return latest_price, hist_data, latest_rsi, info\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                if \"429\" in str(e):\n",
    "                    wait_time = self.retry_delay * (attempt + 1)\n",
    "                    print(f\"Rate limit hit for {symbol}, waiting {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                print(f\"Error fetching data for {symbol}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {symbol}: {e}\")\n",
    "            \n",
    "            if attempt == self.max_retries - 1:\n",
    "                return None, None, None, None\n",
    "            time.sleep(random.uniform(1, 3))\n",
    "\n",
    "    def _calculate_technical_indicators(self, hist_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Calculate technical indicators with error handling\"\"\"\n",
    "        try:\n",
    "            if len(hist_data) >= 9:\n",
    "                hist_data['EMA_9'] = self.calculate_ema(hist_data, length=9)\n",
    "            if len(hist_data) >= 21:\n",
    "                hist_data['EMA_21'] = self.calculate_ema(hist_data, length=21)\n",
    "            if len(hist_data) >= 50:\n",
    "                hist_data['EMA_50'] = self.calculate_ema(hist_data, length=50)\n",
    "                hist_data['TEMA_50'] = self.calculate_tema(hist_data, length=50)\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating technical indicators: {e}\")\n",
    "            for indicator in ['EMA_9', 'EMA_21', 'EMA_50', 'TEMA_50']:\n",
    "                hist_data[indicator] = float('nan')\n",
    "        return hist_data\n",
    "\n",
    "    def _process_stock_info(self, symbol: str, exchange: str, latest_price: float, \n",
    "                           hist_data: pd.DataFrame, latest_rsi: float, info: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Process and format stock information\"\"\"\n",
    "        stock_info = {\n",
    "            'Symbol': symbol,\n",
    "            'Exchange': exchange,\n",
    "            'Company_Name': info.get('longName', 'N/A'),\n",
    "            'Latest_Price': latest_price,\n",
    "            'RSI': latest_rsi,\n",
    "            'Date': datetime.now().strftime('%Y-%m-%d')\n",
    "        }\n",
    "        \n",
    "        # Add technical indicators\n",
    "        for indicator in ['EMA_9', 'EMA_21', 'EMA_50', 'TEMA_50']:\n",
    "            stock_info[indicator] = hist_data[indicator].iloc[-1] if indicator in hist_data else 'N/A'\n",
    "        \n",
    "        # Add other info fields\n",
    "        info_fields = {\n",
    "            'Volume': ('Volume', hist_data['Volume'].iloc[-1] if 'Volume' in hist_data else 0),\n",
    "            'Market_Cap': ('marketCap', 'N/A'),\n",
    "            'PE_Ratio': ('trailingPE', 'N/A'),\n",
    "            'EPS': ('trailingEps', 'N/A'),\n",
    "            'Dividend_Yield': ('dividendYield', 'N/A'),\n",
    "            'Book_Value': ('bookValue', 'N/A'),\n",
    "            'Sector': ('sector', 'N/A'),\n",
    "            'Industry': ('industry', 'N/A'),\n",
    "            '52W_High': ('fiftyTwoWeekHigh', 'N/A'),\n",
    "            '52W_Low': ('fiftyTwoWeekLow', 'N/A'),\n",
    "            'Beta': ('beta', 'N/A'),\n",
    "            'Previous_Close': ('previousClose', 'N/A'),\n",
    "            'Open': ('open', 'N/A'),\n",
    "            'Day_High': ('dayHigh', 'N/A'),\n",
    "            'Day_Low': ('dayLow', 'N/A')\n",
    "        }\n",
    "        \n",
    "        for key, (info_key, default) in info_fields.items():\n",
    "            stock_info[key] = info.get(info_key, default)\n",
    "        \n",
    "        return stock_info\n",
    "\n",
    "    def process_stock_batch(self, batch_data: Tuple[List[str], str]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Process a batch of stocks with rate limiting\"\"\"\n",
    "        symbols, exchange = batch_data\n",
    "        results = []\n",
    "        \n",
    "        # Process in smaller batches\n",
    "        for i in range(0, len(symbols), self.batch_size):\n",
    "            batch_symbols = symbols[i:i + self.batch_size]\n",
    "            print(f\"Processing batch {i//self.batch_size + 1} of {len(symbols)//self.batch_size + 1}\")\n",
    "            \n",
    "            with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "                futures = {executor.submit(self.get_stock_data, symbol, exchange): symbol \n",
    "                          for symbol in batch_symbols}\n",
    "                \n",
    "                for future in futures:\n",
    "                    symbol = futures[future]\n",
    "                    try:\n",
    "                        stock_data = future.result()\n",
    "                        if all(v is not None for v in stock_data):\n",
    "                            latest_price, hist_data, latest_rsi, info = stock_data\n",
    "                            stock_info = self._process_stock_info(symbol, exchange, latest_price, \n",
    "                                                                hist_data, latest_rsi, info)\n",
    "                            results.append(stock_info)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {symbol}: {e}\")\n",
    "            \n",
    "            # Add delay between batches\n",
    "            time.sleep(random.uniform(2, 5))\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def run_daily_analysis(self):\n",
    "        \"\"\"Run daily analysis with Excel output\"\"\"\n",
    "        current_date = datetime.now().strftime('%Y%m%d')\n",
    "        \n",
    "        print(\"Loading stock lists...\")\n",
    "        nse_symbols = self.download_nse_stocks()\n",
    "        bse_symbols = self.download_bse_stocks()\n",
    "\n",
    "        print(f\"\\nAnalyzing {len(nse_symbols)} NSE and {len(bse_symbols)} BSE stocks\")\n",
    "\n",
    "        for exchange, symbols in [('NSE', nse_symbols), ('BSE', bse_symbols)]:\n",
    "            batch_data = (symbols, exchange)\n",
    "            results = self.process_stock_batch(batch_data)\n",
    "            \n",
    "            if results:\n",
    "                excel_file = os.path.join(\n",
    "                    self.results_dir,\n",
    "                    f'{exchange.lower()}_analysis_{current_date}.xlsx'\n",
    "                )\n",
    "                \n",
    "                results_df = pd.DataFrame(results)\n",
    "                \n",
    "                with pd.ExcelWriter(excel_file, engine='xlsxwriter') as writer:\n",
    "                    results_df.to_excel(writer, sheet_name='All Stocks', index=False)\n",
    "                    \n",
    "                    high_rsi = results_df[results_df['RSI'] >= 40].sort_values('RSI', ascending=False)\n",
    "                    high_rsi.to_excel(writer, sheet_name='High RSI Stocks', index=False)\n",
    "                    \n",
    "                    workbook = writer.book\n",
    "                    header_format = workbook.add_format({\n",
    "                        'bold': True,\n",
    "                        'text_wrap': True,\n",
    "                        'valign': 'top',\n",
    "                        'bg_color': '#D9E1F2',\n",
    "                        'border': 1\n",
    "                    })\n",
    "                    \n",
    "                    for worksheet in writer.sheets.values():\n",
    "                        worksheet.set_column('A:Z', 15)\n",
    "                        for col_num, value in enumerate(results_df.columns.values):\n",
    "                            worksheet.write(0, col_num, value, header_format)\n",
    "\n",
    "                print(f\"\\n{exchange} analysis complete. Results saved to {excel_file}\")\n",
    "                \n",
    "                print(f\"\\n{exchange} Stocks with RSI >= 40:\")\n",
    "                for _, row in high_rsi.iterrows():\n",
    "                    print(colored(\n",
    "                        f\"{row['Symbol']} ({row['Company_Name']}): RSI = {row['RSI']:.2f}, \"\n",
    "                        f\"Price = ₹{row['Latest_Price']:.2f}\",\n",
    "                        'green', attrs=['bold']\n",
    "                    ))\n",
    "\n",
    "        print(f\"\\nDaily analysis complete. Results saved in {self.results_dir}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = StockAnalyzer()\n",
    "    analyzer.run_daily_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
